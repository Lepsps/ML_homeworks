# Домашняя работа №2: Классификация клиентов банка

## Описание проекта

Данный проект выполнен в рамках домашнего задания по курсу "Машинное обучение". Целью работы является построение и оценка моделей бинарной классификации для предсказания отклика клиентов на предложение о срочном депозите. Работа реализована в виде Jupyter ноутбука (`classification_task.ipynb`) и следует основным этапам пайплайна машинного обучения.

## Задача

**Бизнес-задача:** Оптимизировать маркетинговую кампанию банка путем выявления клиентов, наиболее склонных к открытию срочного депозита по результатам телефонного звонка.

**Задача машинного обучения:** Построить модель бинарной классификации, которая на основе данных о клиенте и предыдущих контактах предсказывает значение целевой переменной `deposit` ('yes' или 'no').

## Используемый датасет

Для решения задачи был использован датасет **"Bank Marketing Dataset"**. Он содержит информацию о клиентах португальского банка, их демографические данные, историю взаимодействия с банком и результат текущей маркетинговой кампании.

**Ссылка на датасет:** [https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset/data](https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset/data)

Данные для ноутбука загружаются напрямую по URL из публичного репозитория, что обеспечивает полную воспроизводимость.

## Этапы работы

Ноутбук `classification_task.ipynb` содержит следующие шаги:

1.  **Постановка задачи:** Описание бизнес-контекста и задачи машинного обучения.
2.  **Загрузка и первичный анализ данных:** Чтение данных и первое знакомство со структурой.
3.  **Разбиение на выборки:** Данные разделены на обучающую (80%) и тестовую (20%) выборки со стратификацией по целевой переменной.
4.  **Исследовательский анализ данных (EDA):**
    *   Расчет описательных статистик.
    *   Анализ баланса классов (соотношение ~47/53).
    *   Визуализация распределений ключевых признаков (возраст, профессия, семейное положение).
    *   Построение матрицы корреляции для выявления линейных зависимостей.
5.  **Предобработка данных:**
    *   Анализ и обработка пропущенных значений (включая "скрытые" пропуски `'unknown'`). Столбец `poutcome` был удален из-за большого количества пропусков.
    *   Кодирование категориальных признаков с помощью `OneHotEncoder`.
    *   Масштабирование числовых признаков с помощью `StandardScaler`.
6.  **Обучение и оценка моделей:**
    *   **k-ближайших соседей (k-NN):** С подбором оптимального `k` через `GridSearchCV`.
    *   **Логистическая регрессия:** Используется как baseline-модель.
    *   **Случайный лес (Random Forest):** Более сложная ансамблевая модель.
7.  **Сравнение моделей и выводы:** На основе метрик `precision`, `recall` и `f1-score` для целевого класса 'yes' производится сравнение эффективности моделей и формулируются итоговые выводы.

## Результаты

В ходе работы были протестированы три модели. Наилучшее качество по совокупности метрик продемонстрировала модель **Случайный лес (Random Forest)**, достигнув на тестовой выборке **f1-score = 0.85** для целевого класса 'yes'. Эта модель рекомендуется для использования в решении поставленной бизнес-задачи.

## Стек технологий

*   Python 3
*   Pandas
*   NumPy
*   Matplotlib
*   Seaborn
*   Scikit-learn
